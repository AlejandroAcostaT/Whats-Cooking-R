Ry[j] <- TP/P
print(fPrev)
labs[j] = fPrev
fPrev = scores[i]
j = j + 1
}
if(real[i]==target){
TP = TP + 1
}else{
FP = FP + 1
}
i = i + 1
}
Rx[j] <- FP/N
Ry[j] <- TP/P
labs[j] = 1.0
plot(Rx, Ry, main = "ROC Curve", xlim = c(-0.005, 1.005), ylim = c(-0.005, 1.005), xlab = "FP-RATE", ylab = "TP-Rate", pch=16, col="red")
lines(Rx, Ry, lty=5)
lines(c(-2,2),c(-2,2), lty=5, col=16)
text(Rx+0.04, Ry+0.04, labels = labs)
}
generate_ROC(scores, real, target)
generate_ROC = function(scores, real, target){
# Generar curva
real = real[order(scores, decreasing = T)]
scores = sort(scores, decreasing = T)
t = table(real)
l = length(real)
P = t[[target]]
N = l - P
FP = 0
TP = 0
Rx = c()
Ry = c()
fPrev = -Inf
i = 1
j = 1
labs = c()
while(i<=length(real)){
if(scores[i] != fPrev){
Rx[j] <- FP/N
Ry[j] <- TP/P
print(fPrev)
labs[j] = fPrev
fPrev = scores[i]
j = j + 1
}
if(real[i]==target){
TP = TP + 1
}else{
FP = FP + 1
}
i = i + 1
}
Rx[j] <- FP/N
Ry[j] <- TP/P
labs[j] = 1.0
plot(Rx, Ry, main = "ROC Curve", xlim = c(-0.005, 1.005), ylim = c(-0.02, 1.02), xlab = "FP-RATE", ylab = "TP-Rate", pch=16, col="red")
lines(Rx, Ry, lty=5)
lines(c(-2,2),c(-2,2), lty=5, col=16)
text(Rx+0.04, Ry+0.04, labels = labs)
}
generate_ROC(scores, real, target)
generate_ROC = function(scores, real, target){
# Generar curva
real = real[order(scores, decreasing = T)]
scores = sort(scores, decreasing = T)
t = table(real)
l = length(real)
P = t[[target]]
N = l - P
FP = 0
TP = 0
Rx = c()
Ry = c()
fPrev = -Inf
i = 1
j = 1
labs = c()
while(i<=length(real)){
if(scores[i] != fPrev){
Rx[j] <- FP/N
Ry[j] <- TP/P
print(fPrev)
labs[j] = fPrev
fPrev = scores[i]
j = j + 1
}
if(real[i]==target){
TP = TP + 1
}else{
FP = FP + 1
}
i = i + 1
}
Rx[j] <- FP/N
Ry[j] <- TP/P
labs[j] = 1.0
plot(Rx, Ry, main = "ROC Curve", xlim = c(-0.005, 1.005), ylim = c(-0.05, 1.05), xlab = "FP-RATE", ylab = "TP-Rate", pch=16, col="red")
lines(Rx, Ry, lty=5)
lines(c(-2,2),c(-2,2), lty=5, col=16)
text(Rx+0.04, Ry+0.04, labels = labs)
}
generate_ROC(scores, real, target)
generate_ROC = function(scores, real, target){
# Generar curva
real = real[order(scores, decreasing = T)]
scores = sort(scores, decreasing = T)
t = table(real)
l = length(real)
P = t[[target]]
N = l - P
FP = 0
TP = 0
Rx = c()
Ry = c()
fPrev = -Inf
i = 1
j = 1
labs = c()
while(i<=length(real)){
if(scores[i] != fPrev){
Rx[j] <- FP/N
Ry[j] <- TP/P
print(fPrev)
labs[j] = fPrev
fPrev = scores[i]
j = j + 1
}
if(real[i]==target){
TP = TP + 1
}else{
FP = FP + 1
}
i = i + 1
}
Rx[j] <- FP/N
Ry[j] <- TP/P
labs[j] = 1.0
plot(Rx, Ry, main = "ROC Curve", xlim = c(-0.005, 1.005), ylim = c(-0.05, 1.05), xlab = "FP-RATE", ylab = "TP-Rate", pch=16, col="red")
lines(Rx, Ry, lty=5)
lines(c(-2,2),c(-2,2), lty=5, col=16)
text(Rx+0.025, Ry+0.025, labels = labs)
}
generate_ROC(scores, real, target)
generate_ROC(scores, real, target)
botIndex
#Lectura de la etrada
periodico = read.csv("periodico.csv", stringsAsFactors = FALSE)
items = periodico$articles
#Se crean dos listas para el preprocesamiento de la data
temas = c("deportes", "politica", "variedades", "internacional",
"nacionales", "sucesos", "comunidad", "negocios", "opinion")
articulos = c("articulo1", "articulo2", "articulo3", "articulo4",
"articulo5", "articulo6", "articulo7", "articulo8",
"articulo9")
##Preprocesamiento de los datos
#Ciclo para preprocesar la data
arts = c()
for (item in items) {
x = gsub('[^[:alnum:] ]','' ,toString(item))
x = (as.numeric(unlist(unlist(strsplit(x, "[^0-9]+")))))
art = paste(toString(temas[((x[2]-1)/9)+1]),
toString(articulos[((x[2]-1)%%9)+1])
, sep="/")
if(length(x)>2){
for(i in (3:length(x))){
art = paste(art,
paste(toString(temas[((x[i]-1)/9)+1]),
toString(articulos[((x[i]-1)%%9)+1])
, sep="/"),
sep=",")
}
}
arts = c(arts, art)
}
##Buscar numero de Bots:
l = length(periodico[,1])
bots = c()
botIndex = c()
times = c()
index = c()
for(i in (1:l)){
secs = difftime(periodico$exit[i],periodico$entry[i], units = "secs")
if(secs <= 20){
bots = c(bots, i)
botIndex = c(botIndex, i)
}else{
times = c(times, secs)
index = c(index, i)
}
}
length(bots)
#Lectura de la etrada
periodico = read.csv("periodico.csv", stringsAsFactors = FALSE)
items = periodico$articles
#Se crean dos listas para el preprocesamiento de la data
temas = c("deportes", "politica", "variedades", "internacional",
"nacionales", "sucesos", "comunidad", "negocios", "opinion")
articulos = c("articulo1", "articulo2", "articulo3", "articulo4",
"articulo5", "articulo6", "articulo7", "articulo8",
"articulo9")
##Preprocesamiento de los datos
#Ciclo para preprocesar la data
arts = c()
for (item in items) {
x = gsub('[^[:alnum:] ]','' ,toString(item))
x = (as.numeric(unlist(unlist(strsplit(x, "[^0-9]+")))))
art = paste(toString(temas[((x[2]-1)/9)+1]),
toString(articulos[((x[2]-1)%%9)+1])
, sep="/")
if(length(x)>2){
for(i in (3:length(x))){
art = paste(art,
paste(toString(temas[((x[i]-1)/9)+1]),
toString(articulos[((x[i]-1)%%9)+1])
, sep="/"),
sep=",")
}
}
arts = c(arts, art)
}
##Buscar numero de Bots:
l = length(periodico[,1])
bots = c()
botIndex = c()
times = c()
index = c()
for(i in (1:l)){
secs = difftime(periodico$exit[i],periodico$entry[i], units = "secs")
if(secs <= 20){
bots = c(bots, i)
botIndex = c(botIndex, i)
}else{
times = c(times, secs)
index = c(index, i)
}
}
#####################################
#         Parte 1 - articulos
#####################################
#Lectura de la etrada
periodico = read.csv("periodico.csv", stringsAsFactors = FALSE)
items = periodico$articles
#Se crean dos listas para el preprocesamiento de la data
temas = c("deportes", "politica", "variedades", "internacional",
"nacionales", "sucesos", "comunidad", "negocios", "opinion")
articulos = c("articulo1", "articulo2", "articulo3", "articulo4",
"articulo5", "articulo6", "articulo7", "articulo8",
"articulo9")
##Preprocesamiento de los datos
#Ciclo para preprocesar la data
arts = c()
for (item in items) {
x = gsub('[^[:alnum:] ]','' ,toString(item))
x = (as.numeric(unlist(unlist(strsplit(x, "[^0-9]+")))))
art = paste(toString(temas[((x[2]-1)/9)+1]),
toString(articulos[((x[2]-1)%%9)+1])
, sep="/")
if(length(x)>2){
for(i in (3:length(x))){
art = paste(art,
paste(toString(temas[((x[i]-1)/9)+1]),
toString(articulos[((x[i]-1)%%9)+1])
, sep="/"),
sep=",")
}
}
arts = c(arts, art)
}
##Buscar numero de Bots:
l = length(periodico[,1])
bots = c()
botIndex = c()
times = c()
index = c()
for(i in (1:l)){
secs = difftime(periodico$exit[i],periodico$entry[i], units = "secs")
if(secs <= 20){
bots = c(bots, i)
botIndex = c(botIndex, i)
}else{
times = c(times, secs)
index = c(index, i)
}
}
setwd("~/UCV/Semestre IX/Data Mining/recomendacion-modelos")
#####################################
#         Parte 1 - articulos
#####################################
#Lectura de la etrada
periodico = read.csv("periodico.csv", stringsAsFactors = FALSE)
items = periodico$articles
#Se crean dos listas para el preprocesamiento de la data
temas = c("deportes", "politica", "variedades", "internacional",
"nacionales", "sucesos", "comunidad", "negocios", "opinion")
articulos = c("articulo1", "articulo2", "articulo3", "articulo4",
"articulo5", "articulo6", "articulo7", "articulo8",
"articulo9")
##Preprocesamiento de los datos
#Ciclo para preprocesar la data
arts = c()
for (item in items) {
x = gsub('[^[:alnum:] ]','' ,toString(item))
x = (as.numeric(unlist(unlist(strsplit(x, "[^0-9]+")))))
art = paste(toString(temas[((x[2]-1)/9)+1]),
toString(articulos[((x[2]-1)%%9)+1])
, sep="/")
if(length(x)>2){
for(i in (3:length(x))){
art = paste(art,
paste(toString(temas[((x[i]-1)/9)+1]),
toString(articulos[((x[i]-1)%%9)+1])
, sep="/"),
sep=",")
}
}
arts = c(arts, art)
}
##Buscar numero de Bots:
l = length(periodico[,1])
bots = c()
botIndex = c()
times = c()
index = c()
for(i in (1:l)){
secs = difftime(periodico$exit[i],periodico$entry[i], units = "secs")
if(secs <= 20){
bots = c(bots, i)
botIndex = c(botIndex, i)
}else{
times = c(times, secs)
index = c(index, i)
}
}
length(bots)
length(arts[!a%in%bots])
length(arts[!arts%in%bots])
length(bots)
length(arts[-bots])
arts2=arts[-bots]
arts2
train <- fromJSON("train.json", flatten = TRUE)
library("jsonlite")
train <- fromJSON("train.json", flatten = TRUE)
library("jsonlite")
library("rpart")
library("tm")
library("rpart.plot")
library("class")
library("caret")
train <- fromJSON("train.json", flatten = TRUE)
train <- fromJSON(train.json, flatten = TRUE)
setwd("~/UCV/Semestre IX/Data Mining/WhatsCooking")
train <- fromJSON("train.json", flatten = TRUE)
ingredientes <- train$ingredients
ingredientes <- unlist(ingredientes)
ingredientes <- sort(ingredientes)
tabla <-as.data.frame(table(ingredientes))
View(tabla)
View(train)
ListaDeingredientes <- unique(ingredientes)
ListaDeingredientes
test <- fromJSON("test.json", flatten = TRUE)
ingredientesTest <- test$ingredients
ingredientesTest <- unlist(ingredientesTest)
ingredientesTest <- sort(ingredientesTest)
tablaTest <-as.data.frame(table(ingredientesTest))
View(tablaTest)
ingredientes <- Corpus(VectorSource(train$ingredients))
ingredientes <- Corpus(VectorSource(train$ingredients))
ingredientsDTM <- DocumentTermMatrix(ingredients)
ingredientsDTM <- DocumentTermMatrix(ingredientes)
ingredientsDTM
ingredientesDTM <- DocumentTermMatrix(ingredientes)
sparse <- removeSparseTerms(ingredientesDTM, 0.99)
ingredientsDTM <- as.data.frame(as.matrix(sparse))
View(ingredientsDTM)
ingredientes <- train$ingredients
ingredientes <- unlist(ingredientes)
ingredientes <- sort(ingredientes)
ListaDeingredientes <- unique(ingredientes)
ListaDeingredientes <- as.data.frame(unique(ingredientes))
View(ListaDeingredientes)
ingredients <- Corpus(VectorSource(train$ingredients))
ingredientsDTM <- DocumentTermMatrix(ingredients)
inspect(ingredientsDTM)
inspect(ingredientsDTM)
table(ingredientsDTM)
ingredientsDTM
sparse <- removeSparseTerms(ingredientsDTM, 0.99)
ingredientsDTM <- as.data.frame(as.matrix(sparse))
ingredientsDTM$cuisine <- as.factor(train$cuisine)
View(ingredientsDTM)
ingredientsDTM <- DocumentTermMatrix(ingredients)
table(ingredientsDTM)
sparse <- removeSparseTerms(ingredientsDTM, 0.995)
ingredientsDTM <- as.data.frame(as.matrix(sparse))
ingredientsDTM <- DocumentTermMatrix(ingredients)
as.factor(train$cuisine)
train <- fromJSON("train.json", flatten = TRUE)
test <- fromJSON("test.json", flatten = TRUE)
#add dependent variable
test$cuisine <- NA
#combine data set
combi <- rbind(train, test)
######################################
#         Preprocess Data            #
######################################
#create corpus
corpus <- Corpus(VectorSource(combi$ingredients))
#convert text to lowercase
corpus <- tm_map(corpus, tolower)
corpus[[1]]
View(train)
corpus <- tm_map(corpus, removePunctuation)
corpus[[1]]
#remove stopwords
corpus <- tm_map(corpus, removeWords, c(stopwords('english')))
corpus[[1]]
#remove whitespaces
corpus <- tm_map(corpus, stripWhitespace)
corpus[[1]]
#perform stemming
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, stemDocument)
library("tm")
corpus <- tm_map(corpus, stemDocument)
install.packages("SnowballC")
corpus <- tm_map(corpus, stemDocument)
corpus[[1]]
frequencies <- DocumentTermMatrix(corpus)
corpus <- tm_map(corpus, PlainTextDocument)
frequencies <- DocumentTermMatrix(corpus)
frequencies
sparse <- removeSparseTerms(frequencies, 1 - 3/nrow(frequencies))
dim(sparse)
wf <- data.frame(word = names(freq), freq = freq)
freq <- colSums(as.matrix(frequencies))
wf <- data.frame(word = names(freq), freq = freq)
head(wf)
newsparse <- as.data.frame(as.matrix(sparse))
dim(newsparse)
#check if all words are appropriate
colnames(newsparse) <- make.names(colnames(newsparse))
#check for the dominant dependent variable
table(train$cuisine)
mytrain <- newsparse[1:nrow(train),]
mytest <- newsparse[-(1:nrow(train)),]
View(mytrain)
View(mytest)
table(mytest$cuisine)
(mytest$cuisine)
table(mytrain$cuisine)
newsparse$cuisine <- as.factor(c(train$cuisine, rep('italian', nrow(test))))
#split data
mytrain <- newsparse[1:nrow(train),]
mytest <- newsparse[-(1:nrow(train)),]
table(mytrain$cuisine)
table(mytest$cuisine)
set.seed(9347)
cartModelFit <- rpart(cuisine ~ ., data = mytrain, method = "class")
prp(cartModelFit)
cartPredict <- predict(cartModelFit, newdata = mytest, type = "class")
cartCM <- confusionMatrix(cartPredict, testing$cuisine)
cartCM <- confusionMatrix(cartPredict, mytest$cuisine)
cartCM
mytest <- mytest[-"cuisine"]
mytest$cuisine <- NULL
mytest$cuisine
cartPredict <- predict(cartModelFit, newdata = mytest, type = "class")
cartCM <- confusionMatrix(cartPredict, mytest$cuisine)
mytrain <- newsparse[1:nrow(train),]
mytest <- newsparse[-(1:nrow(train)),]
cartPredict <- predict(cartModelFit, newdata = mytest, type = "class")
cartCM <- confusionMatrix(cartPredict, mytest$cuisine)
cartCM
cartModelFit
cartPredict
cartPredict[1]
df <- as.data.frame(cartPredict)
View(df)
cartPredict[1,1]
cartPredict[[1]]
cartPredict[[0]]
cartPredict[[1]]
df <- data.frame(cartPredict)
View(df)
for(i in cartPredict){
print(i)
}
j=1
id <- c()
cuisine <-c()
for(i in cartPredict){
id<-c(id,j)
cuisine<-c(cuisine, i)
j=j+1
}
cartPredict[[1]]
df <- data.frame(id,cuisine)
View(df)
View(test)
cuisine <-c()
for(i in cartPredict){
cuisine<-c(cuisine, i)
}
cartPredict[[1]]
df <- data.frame(test$id,cuisine)
write.csv(df, file = "Output.csv")
write.csv(df, file = "Output.csv")
write.csv(df, file = "Output.csv")
